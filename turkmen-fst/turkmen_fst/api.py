# -*- coding: utf-8 -*-
"""
TurkmenFST â€” FastAPI REST API (api.py)

Endpoints:
    GET  /              â€” API kullanÄ±m kÄ±lavuzu (HTML)
    POST /generate/noun â€” Ä°sim Ã§ekimi
    POST /generate/verb â€” Fiil Ã§ekimi
    POST /generate      â€” BirleÅŸik Ã¼retim (isim veya fiil)
    POST /analyze       â€” Morfolojik analiz
    GET  /lexicon/{word} â€” SÃ¶zlÃ¼k sorgusu
    GET  /health        â€” SaÄŸlÄ±k kontrolÃ¼

Swagger UI: http://localhost:8000/docs
"""

from __future__ import annotations
import os
import re
from functools import lru_cache
from typing import Optional, Literal

try:
    from fastapi import FastAPI, HTTPException
    from fastapi.middleware.cors import CORSMiddleware
    from fastapi.responses import HTMLResponse
    from pydantic import BaseModel, Field
    HAS_FASTAPI = True
except ImportError:
    HAS_FASTAPI = False

from turkmen_fst.phonology import PhonologyRules
from turkmen_fst.lexicon import Lexicon, POS_DISPLAY
from turkmen_fst.morphotactics import VerbMorphotactics
from turkmen_fst.generator import MorphologicalGenerator
from turkmen_fst.analyzer import MorphologicalAnalyzer


# ==============================================================================
#  TOKENIZER & SPELLCHECK YARDIMCILARI
# ==============================================================================

_WORD_RE = re.compile(r"[a-zA-ZÃ§Ã‡Ã¤Ã„Ã¶Ã–Ã¼ÃœÅˆÅ‡Ã½ÃÅŸÅÅ¾Å½Ã®Ã'-]+", re.UNICODE)


def tokenize(text: str) -> list[dict]:
    """
    Metni kelimelere ayÄ±rÄ±r. Her kelime iÃ§in konum bilgisi de dÃ¶ndÃ¼rÃ¼r.

    Returns:
        [{"word": "kitabym", "start": 0, "end": 7}, ...]
    """
    tokens = []
    for m in _WORD_RE.finditer(text):
        tokens.append({"word": m.group(), "start": m.start(), "end": m.end()})
    return tokens


def _edit_distance(a: str, b: str) -> int:
    """Ä°ki string arasÄ±ndaki Levenshtein edit distance."""
    if len(a) < len(b):
        return _edit_distance(b, a)
    if len(b) == 0:
        return len(a)
    prev = list(range(len(b) + 1))
    for i, ca in enumerate(a):
        curr = [i + 1]
        for j, cb in enumerate(b):
            cost = 0 if ca == cb else 1
            curr.append(min(curr[j] + 1, prev[j + 1] + 1, prev[j] + cost))
        prev = curr
    return prev[-1]


def _find_similar_roots(word: str, lexicon: Lexicon,
                        max_distance: int = 2, max_results: int = 10) -> list[str]:
    """
    SÃ¶zlÃ¼kte edit distance â‰¤ max_distance olan kelimeleri bulur.
    Performans iÃ§in kelime uzunluÄŸuna gÃ¶re filtreleme yapar.
    """
    w = word.lower()
    wlen = len(w)
    candidates = []

    for key in lexicon._entries:
        # Uzunluk farkÄ± edit distance'dan bÃ¼yÃ¼kse atla
        if abs(len(key) - wlen) > max_distance:
            continue
        dist = _edit_distance(w, key)
        if 0 < dist <= max_distance:
            candidates.append((dist, key))

    candidates.sort(key=lambda x: (x[0], x[1]))
    return [c[1] for c in candidates[:max_results]]


def generate_suggestions(wrong_word: str, analyzer: MorphologicalAnalyzer,
                         lexicon: Lexicon, max_suggestions: int = 5) -> list[str]:
    """
    YanlÄ±ÅŸ yazÄ±lmÄ±ÅŸ kelime iÃ§in Ã¶neri Ã¼retir.

    Strateji:
    1. Edit distance â‰¤ 2 olan sÃ¶zlÃ¼k kÃ¶klerini bul
    2. Her kÃ¶ke orijinal kelimeye en yakÄ±n Ã§ekim formlarÄ±nÄ± Ã¼ret
    3. En yakÄ±n formlarÄ± sÄ±rala ve dÃ¶ndÃ¼r
    """
    similar_roots = _find_similar_roots(wrong_word, lexicon, max_distance=2, max_results=15)

    suggestions = set()
    for root in similar_roots:
        # KÃ¶kÃ¼n kendisi bir Ã¶neri olabilir
        suggestions.add(root)

        # KÃ¶kÃ¼n Ã§ekim formlarÄ±nÄ± Ã¼retip orijinal kelimeye yakÄ±nlÄ±ÄŸa gÃ¶re sÄ±rala
        # Ama tÃ¼m paradigmayÄ± Ã¼retmek pahalÄ±, sadece kÃ¶kÃ¼ Ã¶neriyoruz
        # Ä°leride buraya tam paradigma eklenebilir

    # Orijinal kelimeye en yakÄ±n olanlarÄ± sÄ±rala
    ranked = sorted(suggestions, key=lambda s: _edit_distance(s.lower(), wrong_word.lower()))
    return ranked[:max_suggestions]


# ==============================================================================
#  SÃ–ZLÃœK YÃœKLEME
# ==============================================================================

def _find_lexicon_path() -> str:
    candidates = [
        os.path.join(os.path.dirname(__file__), "..", "data", "turkmence_sozluk.txt"),
        os.path.join(os.path.dirname(__file__), "..", "..", "turkmence_sozluk.txt"),
    ]
    for path in candidates:
        real = os.path.realpath(path)
        if os.path.exists(real):
            return real
    return ""


# Global instances
_lexicon = Lexicon()
_path = _find_lexicon_path()
if _path:
    _lexicon.load(_path)

_generator = MorphologicalGenerator(_lexicon)
_analyzer = MorphologicalAnalyzer(_lexicon)


# ==============================================================================
#  Ä°YELÄ°K GÃ–RÃœNTÃœLEME EÅLEMESÄ°
# ==============================================================================

IYELIK_DISPLAY = {
    "A1": "Dâ‚b", "A2": "Dâ‚‚b", "A3": "Dâ‚ƒb",
    "B1": "Dâ‚k", "B2": "Dâ‚‚k", "B3": "Dâ‚ƒk"
}

MORPHEME_DISPLAY = {
    "PLURAL": "Ã‡okluk (San)",
    "POSSESSIVE": "DegiÅŸlilik (Ä°yelik)",
    "CASE": "DÃ¼ÅŸÃ¼m (Hal)",
    "TENSE": "Zaman",
    "PERSON": "ÅahÄ±s",
    "NEGATION": "Olumsuzluk",
}


def _format_morphemes(morphemes: list, possessive: Optional[str] = None) -> list:
    """Morpheme listesini kullanÄ±cÄ± dostu formata Ã§evirir."""
    result = []
    for category, suffix in morphemes:
        entry = {
            "category": category,
            "display": MORPHEME_DISPLAY.get(category, category),
            "suffix": suffix,
        }
        if category == "POSSESSIVE" and possessive:
            entry["code"] = IYELIK_DISPLAY.get(possessive, possessive)
        result.append(entry)
    return result


# ==============================================================================
#  FASTAPI UYGULAMA
# ==============================================================================

if HAS_FASTAPI:

    API_DESCRIPTION = """
## TÃ¼rkmen TÃ¼rkÃ§esi Morfolojik Analiz ve Sentez API'si

### HÄ±zlÄ± BaÅŸlangÄ±Ã§

**Ä°sim Ã§ekimi** â€” `POST /generate/noun` ile sadece `stem` gÃ¶nderin:
```json
{"stem": "kitap"}
```
SonuÃ§: `kitap` (yalÄ±n hal). Ek parametreler ekleyerek Ã§ekim yapabilirsiniz.

### Parametre KodlarÄ±

#### Ä°yelik (Possessive) KodlarÄ±
| Kod | GÃ¶rÃ¼ntÃ¼leme | AÃ§Ä±klama | Ã–rnek (kitap) |
|-----|-------------|----------|---------------|
| `A1` | Dâ‚b | 1. tekil (meniÅˆ) | kitab**ym** |
| `A2` | Dâ‚‚b | 2. tekil (seniÅˆ) | kitab**yÅˆ** |
| `A3` | Dâ‚ƒb | 3. tekil (onuÅˆ) | kitab**y** |

#### Hal (Case) KodlarÄ±
| Kod | Hal AdÄ± | Soru | Ã–rnek (kitap) |
|-----|---------|------|---------------|
| _(boÅŸ)_ | BaÅŸ (YalÄ±n) | kim? nÃ¤me? | kitap |
| `A2` | EÃ½elik (Ä°lgi) | kimiÅˆ? nÃ¤mÃ¤niÅˆ? | kitab**yÅˆ** |
| `A3` | Barlag (YÃ¶nelme) | kime? nÃ¤mÃ¤? | kitab**a** |
| `A4` | Tabyn (Belirtme) | kimi? nÃ¤mÃ¤ni? | kitab**y** |
| `A5` | Ãerlik (Bulunma) | kimde? nÃ¤mede? | kitap**da** |
| `A6` | Ã‡ykyÅŸ (Ã‡Ä±kma) | kimden? nÃ¤meden? | kitap**dan** |

#### Fiil Zaman KodlarÄ±
| Kod | Zaman | Ã–rnek (gel-) |
|-----|-------|-------------|
| `1` | Anyk Ã–ten (belirli geÃ§miÅŸ) | gel**di**m |
| `2` | DaÅŸ Ã–ten (belirsiz geÃ§miÅŸ) | gel**ipdi**m |
| `3` | Dowamly Ã–ten (sÃ¼rekli geÃ§miÅŸ) | gel**Ã½Ã¤rdi**m |
| `4` | Umumy HÃ¤zirki (geniÅŸ ÅŸimdiki) | gel**Ã½Ã¤r**in |
| `5` | Anyk HÃ¤zirki (kesin ÅŸimdiki) | _(yardÄ±mcÄ± fiil)_ |
| `6` | MÃ¤lim Geljek (belirli gelecek) | men gel**jek** |
| `7` | NÃ¤mÃ¤lim Geljek (belirsiz gelecek) | gel**er**in |

#### ÅahÄ±s KodlarÄ±
| Kod | Zamiri | AÃ§Ä±klama |
|-----|--------|----------|
| `A1` | Men | 1. tekil |
| `A2` | Sen | 2. tekil |
| `A3` | Ol | 3. tekil |
| `B1` | Biz | 1. Ã§oÄŸul |
| `B2` | Siz | 2. Ã§oÄŸul |
| `B3` | Olar | 3. Ã§oÄŸul |
"""

    app = FastAPI(
        title="TurkmenFST API",
        description=API_DESCRIPTION,
        version="1.0.0",
        docs_url="/docs",
        redoc_url="/redoc"
    )

    # CORS
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

    # ---- Request / Response modelleri ----

    class NounGenerateRequest(BaseModel):
        """Ä°sim Ã§ekimi isteÄŸi. Sadece `stem` zorunludur, diÄŸerleri opsiyoneldir."""
        stem: str = Field(
            ...,
            description="KÃ¶k kelime (Ã¶r. kitap, adam, burun)",
            json_schema_extra={"example": "kitap"}
        )
        plural: bool = Field(
            False,
            description="Ã‡oÄŸul eki eklensin mi? (true â†’ kitaplar)"
        )
        possessive: Optional[str] = Field(
            None,
            description="Ä°yelik kodu: A1 (meniÅˆ), A2 (seniÅˆ), A3 (onuÅˆ). BoÅŸ bÄ±rakÄ±labilir."
        )
        poss_type: str = Field(
            "tek",
            description="Ä°yelik tipi: 'tek' (tekil) veya 'cog' (Ã§oÄŸul)"
        )
        case: Optional[str] = Field(
            None,
            description="Hal kodu: A2 (ilgi), A3 (yÃ¶nelme), A4 (belirtme), A5 (bulunma), A6 (Ã§Ä±kma). BoÅŸ bÄ±rakÄ±labilir."
        )

        model_config = {
            "json_schema_extra": {
                "examples": [
                    {
                        "summary": "YalÄ±n hal (en basit)",
                        "description": "Sadece kÃ¶k kelime â€” ek yok",
                        "value": {"stem": "kitap"}
                    },
                    {
                        "summary": "Ä°yelik Ã§ekimi",
                        "description": "kitap + A1 iyelik â†’ kitabym",
                        "value": {"stem": "kitap", "possessive": "A1"}
                    },
                    {
                        "summary": "Tam Ã§ekim",
                        "description": "kitap + Ã§oÄŸul + A3 iyelik + A2 hal â†’ kitaplarynyÅˆ",
                        "value": {"stem": "kitap", "plural": True, "possessive": "A3", "case": "A2"}
                    }
                ]
            }
        }

    class VerbGenerateRequest(BaseModel):
        """Fiil Ã§ekimi isteÄŸi. stem, tense ve person zorunludur."""
        stem: str = Field(
            ...,
            description="Fiil kÃ¶kÃ¼ (Ã¶r. gel, oka, bar)",
            json_schema_extra={"example": "gel"}
        )
        tense: str = Field(
            ...,
            description="Zaman kodu: 1 (Anyk Ã–ten), 2 (DaÅŸ Ã–ten), 3 (Dowamly Ã–ten), 4 (Umumy HÃ¤zirki), 5 (Anyk HÃ¤zirki), 6 (MÃ¤lim Geljek), 7 (NÃ¤mÃ¤lim Geljek)",
            json_schema_extra={"example": "1"}
        )
        person: str = Field(
            ...,
            description="ÅahÄ±s kodu: A1 (Men), A2 (Sen), A3 (Ol), B1 (Biz), B2 (Siz), B3 (Olar)",
            json_schema_extra={"example": "A1"}
        )
        negative: bool = Field(
            False,
            description="Olumsuz mu? (true â†’ gelmedi)"
        )

        model_config = {
            "json_schema_extra": {
                "examples": [
                    {
                        "summary": "GeÃ§miÅŸ zaman",
                        "description": "gel + geÃ§miÅŸ + 1. tekil â†’ geldim",
                        "value": {"stem": "gel", "tense": "1", "person": "A1"}
                    },
                    {
                        "summary": "Olumsuz ÅŸimdiki",
                        "description": "gel + ÅŸimdiki + 3. tekil + olumsuz â†’ gelmeÃ½Ã¤r",
                        "value": {"stem": "gel", "tense": "4", "person": "A3", "negative": True}
                    }
                ]
            }
        }

    class UnifiedGenerateRequest(BaseModel):
        """BirleÅŸik Ã¼retim isteÄŸi. type='noun' veya type='verb' seÃ§erek kullanÄ±n."""
        type: str = Field(
            "noun",
            description="Kelime tÃ¼rÃ¼: 'noun' (isim) veya 'verb' (fiil)"
        )
        stem: str = Field(
            ...,
            description="KÃ¶k kelime",
            json_schema_extra={"example": "kitap"}
        )
        # Ä°sim parametreleri
        plural: bool = Field(False, description="[Ä°sim] Ã‡oÄŸul eki")
        possessive: Optional[str] = Field(None, description="[Ä°sim] Ä°yelik: A1, A2, A3 (boÅŸ bÄ±rakÄ±labilir)")
        poss_type: str = Field("tek", description="[Ä°sim] Ä°yelik tipi: tek/cog")
        case: Optional[str] = Field(None, description="[Ä°sim] Hal: A2-A6 (boÅŸ bÄ±rakÄ±labilir)")
        # Fiil parametreleri
        tense: Optional[str] = Field(None, description="[Fiil] Zaman kodu: 1-7 (fiil iÃ§in zorunlu)")
        person: Optional[str] = Field(None, description="[Fiil] ÅahÄ±s kodu: A1-B3 (fiil iÃ§in zorunlu)")
        negative: bool = Field(False, description="[Fiil] Olumsuz mu")

        model_config = {
            "json_schema_extra": {
                "examples": [
                    {
                        "summary": "Ä°sim Ã§ekimi",
                        "description": "kitap + iyelik A1 â†’ kitabym",
                        "value": {"type": "noun", "stem": "kitap", "possessive": "A1"}
                    },
                    {
                        "summary": "Fiil Ã§ekimi",
                        "description": "gel + geÃ§miÅŸ + 1. tekil â†’ geldim",
                        "value": {"type": "verb", "stem": "gel", "tense": "1", "person": "A1"}
                    }
                ]
            }
        }

    class GenerateResponse(BaseModel):
        """Ãœretim sonucu."""
        result: str = Field(..., description="Ã‡ekimlenmiÅŸ kelime (Ã¶r. kitabym)")
        breakdown: str = Field(..., description="Ek ayrÄ±mÄ± (Ã¶r. kitap + ym)")
        stem: str = Field(..., description="Orijinal kÃ¶k kelime")
        morphemes: list = Field(..., description="Uygulanan ekler: [{category, display, suffix, code}]")
        valid: bool = Field(..., description="GeÃ§erli bir Ã§ekim mi")

    class AnalyzeRequest(BaseModel):
        """Morfolojik analiz isteÄŸi."""
        word: str = Field(
            ...,
            description="Analiz edilecek Ã§ekimli kelime (Ã¶r. kitabym, kitaplar, geldim)",
            json_schema_extra={"example": "kitabym"}
        )

        model_config = {
            "json_schema_extra": {
                "examples": [
                    {
                        "summary": "Ä°sim analizi",
                        "value": {"word": "kitabym"}
                    },
                    {
                        "summary": "Ã‡oÄŸul isim",
                        "value": {"word": "kitaplar"}
                    },
                    {
                        "summary": "Fiil analizi",
                        "value": {"word": "geldi"}
                    }
                ]
            }
        }

    class AnalyzeSingleResult(BaseModel):
        """Tek bir Ã§Ã¶zÃ¼mleme sonucu."""
        stem: str = Field(..., description="Bulunan kÃ¶k")
        word_type: str = Field(..., description="Kelime tÃ¼rÃ¼: noun/verb/unknown")
        breakdown: str = Field(..., description="Analiz formÃ¼lÃ¼ (Ã¶r. Kitap (KÃ¶k) + ym (Dâ‚b))")
        suffixes: list = Field(..., description="Ek listesi")
        meaning: str = Field("", description="Anlam (eÅŸ sesli kelimeler iÃ§in)")

    class AnalyzeResponse(BaseModel):
        """Ã‡oklu analiz sonucu."""
        word: str = Field(..., description="Orijinal kelime")
        success: bool = Field(..., description="En az bir Ã§Ã¶zÃ¼mleme bulundu mu")
        count: int = Field(..., description="Bulunan Ã§Ã¶zÃ¼mleme sayÄ±sÄ±")
        results: list[AnalyzeSingleResult] = Field(..., description="Ã‡Ã¶zÃ¼mleme sonuÃ§larÄ± listesi")

    class LexiconResponse(BaseModel):
        word: str
        found: bool
        entries: list
        pos_display: Optional[str] = None

    class HealthResponse(BaseModel):
        status: str
        version: str
        lexicon_loaded: bool
        lexicon_words: int

    # ---- Spellcheck Modelleri ----

    class SpellcheckRequest(BaseModel):
        """YazÄ±m denetimi isteÄŸi."""
        text: str = Field(
            ...,
            description="Kontrol edilecek metin (bir veya birden fazla kelime)",
            json_schema_extra={"example": "men kitabym okadym"}
        )

        model_config = {
            "json_schema_extra": {
                "examples": [
                    {
                        "summary": "Basit cÃ¼mle",
                        "value": {"text": "men kitabym okadym"}
                    },
                    {
                        "summary": "HatalÄ± kelimeler",
                        "value": {"text": "kitaplarymzdan mugalym geldy"}
                    }
                ]
            }
        }

    class SpellcheckWordResult(BaseModel):
        """Tek kelime yazÄ±m kontrolÃ¼ sonucu."""
        word: str = Field(..., description="Kontrol edilen kelime")
        correct: bool = Field(..., description="DoÄŸru mu?")
        start: int = Field(..., description="Kelime baÅŸlangÄ±Ã§ pozisyonu")
        end: int = Field(..., description="Kelime bitiÅŸ pozisyonu")
        suggestions: list[str] = Field(default_factory=list,
                                       description="YanlÄ±ÅŸsa Ã¶neri listesi")
        analysis: Optional[str] = Field(None,
                                         description="DoÄŸruysa morfolojik analiz")

    class SpellcheckResponse(BaseModel):
        """YazÄ±m denetimi sonucu."""
        text: str = Field(..., description="Orijinal metin")
        word_count: int = Field(..., description="Kontrol edilen kelime sayÄ±sÄ±")
        error_count: int = Field(..., description="HatalÄ± kelime sayÄ±sÄ±")
        results: list[SpellcheckWordResult] = Field(...,
                                                      description="Kelime bazlÄ± sonuÃ§lar")

    class SpellcheckBatchRequest(BaseModel):
        """Toplu yazÄ±m denetimi â€” kelime listesi."""
        words: list[str] = Field(
            ...,
            description="Kontrol edilecek kelimeler listesi",
            json_schema_extra={"example": ["kitabym", "okadym", "mugalym"]}
        )

    # ---- Endpoints ----

    @app.get("/", response_class=HTMLResponse, tags=["Guide"],
             summary="API KullanÄ±m KÄ±lavuzu")
    async def api_guide():
        """Ana sayfa â€” API kullanÄ±m kÄ±lavuzu (HTML)."""
        return HTMLResponse(content="""
<!DOCTYPE html>
<html lang="tk">
<head>
    <meta charset="utf-8">
    <title>TurkmenFST API</title>
    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
               max-width: 800px; margin: 40px auto; padding: 0 20px; color: #333;
               line-height: 1.6; }
        h1 { color: #1a5f2a; border-bottom: 2px solid #1a5f2a; padding-bottom: 8px; }
        h2 { color: #2d7a3e; margin-top: 32px; }
        code { background: #f4f4f4; padding: 2px 6px; border-radius: 3px; font-size: 0.9em; }
        pre { background: #f8f8f8; border: 1px solid #ddd; border-radius: 6px;
              padding: 16px; overflow-x: auto; }
        table { border-collapse: collapse; width: 100%; margin: 16px 0; }
        th, td { border: 1px solid #ddd; padding: 8px 12px; text-align: left; }
        th { background: #f0f7f0; }
        a { color: #1a5f2a; }
        .example { background: #f0f7f0; border-left: 4px solid #1a5f2a;
                   padding: 12px 16px; margin: 16px 0; border-radius: 0 4px 4px 0; }
        .endpoint { background: #e8f5e9; padding: 4px 8px; border-radius: 4px;
                    font-weight: bold; }
    </style>
</head>
<body>
    <h1>ğŸ‡¹ğŸ‡² TurkmenFST API v1.0</h1>
    <p>TÃ¼rkmen TÃ¼rkÃ§esi Morfolojik Analiz ve Sentez API'si</p>
    <p>ğŸ“– <a href="/docs">Swagger UI (Ä°nteraktif API Belgesi)</a> |
       ğŸ“‹ <a href="/redoc">ReDoc</a></p>

    <h2>HÄ±zlÄ± BaÅŸlangÄ±Ã§</h2>

    <h3>1. Ä°sim Ã‡ekimi</h3>
    <p class="endpoint">POST /generate/noun</p>
    <div class="example">
        <strong>En basit kullanÄ±m â€” sadece kÃ¶k kelime gÃ¶nderin:</strong>
        <pre>curl -X POST http://localhost:8000/generate/noun \\
  -H "Content-Type: application/json" \\
  -d '{"stem": "kitap"}'</pre>
        <strong>Ä°yelik ekli:</strong>
        <pre>{"stem": "kitap", "possessive": "A1"}  â†’ kitabym</pre>
        <strong>Ã‡oÄŸul + hal:</strong>
        <pre>{"stem": "kitap", "plural": true, "case": "A5"}  â†’ kitaplarda</pre>
    </div>

    <h3>2. Fiil Ã‡ekimi</h3>
    <p class="endpoint">POST /generate/verb</p>
    <div class="example">
        <strong>stem + tense + person zorunludur:</strong>
        <pre>{"stem": "gel", "tense": "1", "person": "A1"}  â†’ geldim</pre>
        <strong>Olumsuz:</strong>
        <pre>{"stem": "gel", "tense": "4", "person": "A3", "negative": true}  â†’ gelmeÃ½Ã¤r</pre>
    </div>

    <h3>3. Kelime Analizi</h3>
    <p class="endpoint">POST /analyze</p>
    <div class="example">
        <pre>{"word": "kitabym"}  â†’ kÃ¶k: kitap, ek: ym (Dâ‚b)</pre>
    </div>

    <h3>4. SÃ¶zlÃ¼k Sorgusu</h3>
    <p class="endpoint">GET /lexicon/kitap</p>

    <h3>5. YazÄ±m Denetimi (TÃ„ZE!)</h3>
    <p class="endpoint">POST /spellcheck</p>
    <div class="example">
        <strong>Metin kontrolÃ¼:</strong>
        <pre>{"text": "men kitabym okadym"}</pre>
        <strong>Toplu kontrol:</strong>
        <pre>POST /spellcheck/batch
{"words": ["kitabym", "okadym", "mugalym"]}</pre>
    </div>

    <h3>6. Paradigma Tablosu (TÃ„ZE!)</h3>
    <p class="endpoint">POST /paradigm</p>
    <div class="example">
        <strong>Ä°sim paradigmasÄ±:</strong>
        <pre>{"stem": "kitap", "type": "noun"}</pre>
        <strong>Fiil paradigmasÄ±:</strong>
        <pre>{"stem": "gel", "type": "verb"}</pre>
    </div>

    <h2>Parametre KodlarÄ±</h2>

    <h3>Ä°yelik (DegiÅŸlilik)</h3>
    <table>
        <tr><th>Kod</th><th>GÃ¶sterim</th><th>AÃ§Ä±klama</th><th>Ã–rnek</th></tr>
        <tr><td>A1</td><td>Dâ‚b</td><td>1. tekil (meniÅˆ)</td><td>kitab<b>ym</b></td></tr>
        <tr><td>A2</td><td>Dâ‚‚b</td><td>2. tekil (seniÅˆ)</td><td>kitab<b>yÅˆ</b></td></tr>
        <tr><td>A3</td><td>Dâ‚ƒb</td><td>3. tekil (onuÅˆ)</td><td>kitab<b>y</b></td></tr>
    </table>

    <h3>Hal (DÃ¼ÅŸÃ¼m)</h3>
    <table>
        <tr><th>Kod</th><th>Hal</th><th>Soru</th><th>Ã–rnek</th></tr>
        <tr><td><em>boÅŸ</em></td><td>BaÅŸ (YalÄ±n)</td><td>kim? nÃ¤me?</td><td>kitap</td></tr>
        <tr><td>A2</td><td>EÃ½elik (Ä°lgi)</td><td>kimiÅˆ?</td><td>kitab<b>yÅˆ</b></td></tr>
        <tr><td>A3</td><td>Barlag (YÃ¶nelme)</td><td>kime?</td><td>kitab<b>a</b></td></tr>
        <tr><td>A4</td><td>Tabyn (Belirtme)</td><td>kimi?</td><td>kitab<b>y</b></td></tr>
        <tr><td>A5</td><td>Ãerlik (Bulunma)</td><td>kimde?</td><td>kitap<b>da</b></td></tr>
        <tr><td>A6</td><td>Ã‡ykyÅŸ (Ã‡Ä±kma)</td><td>kimden?</td><td>kitap<b>dan</b></td></tr>
    </table>

    <h3>Fiil ZamanlarÄ±</h3>
    <table>
        <tr><th>Kod</th><th>Zaman</th><th>Ã–rnek (gel-)</tr>
        <tr><td>1</td><td>Anyk Ã–ten</td><td>gel<b>di</b>m</td></tr>
        <tr><td>2</td><td>DaÅŸ Ã–ten</td><td>gel<b>ipdi</b>m</td></tr>
        <tr><td>3</td><td>Dowamly Ã–ten</td><td>gel<b>Ã½Ã¤rdi</b>m</td></tr>
        <tr><td>4</td><td>Umumy HÃ¤zirki</td><td>gel<b>Ã½Ã¤r</b>in</td></tr>
        <tr><td>5</td><td>Anyk HÃ¤zirki</td><td><em>yardÄ±mcÄ± fiil</em></td></tr>
        <tr><td>6</td><td>MÃ¤lim Geljek</td><td>men gel<b>jek</b></td></tr>
        <tr><td>7</td><td>NÃ¤mÃ¤lim Geljek</td><td>gel<b>er</b>in</td></tr>
    </table>

    <h3>ÅahÄ±s KodlarÄ±</h3>
    <table>
        <tr><th>Kod</th><th>Zamir</th></tr>
        <tr><td>A1</td><td>Men (Ben)</td></tr>
        <tr><td>A2</td><td>Sen</td></tr>
        <tr><td>A3</td><td>Ol (O)</td></tr>
        <tr><td>B1</td><td>Biz</td></tr>
        <tr><td>B2</td><td>Siz</td></tr>
        <tr><td>B3</td><td>Olar (Onlar)</td></tr>
    </table>
</body>
</html>
""")

    @app.get("/health", response_model=HealthResponse, tags=["System"],
             summary="Sistem saÄŸlÄ±k kontrolÃ¼")
    async def health():
        """Sistemin Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± ve sÃ¶zlÃ¼k durumunu kontrol eder."""
        return HealthResponse(
            status="ok",
            version="1.0.0",
            lexicon_loaded=_lexicon.is_loaded,
            lexicon_words=_lexicon.word_count
        )

    @app.post("/generate/noun", response_model=GenerateResponse, tags=["Generation"],
              summary="Ä°sim Ã§ekimi (Ã¼retim)")
    async def generate_noun(req: NounGenerateRequest):
        """
        Ä°sim Ã§ekimi yapar.

        **En basit kullanÄ±m** â€” sadece `stem` gÃ¶nderin, diÄŸer alanlarÄ± boÅŸ bÄ±rakÄ±n:
        ```json
        {"stem": "kitap"}
        ```

        **Ä°yelik eklemek iÃ§in** `possessive` alanÄ±nÄ± kullanÄ±n:
        ```json
        {"stem": "kitap", "possessive": "A1"}
        ```
        SonuÃ§: `kitabym` (kitap + ym = Dâ‚b)

        **Ã‡oÄŸul + hal** eklemek iÃ§in:
        ```json
        {"stem": "kitap", "plural": true, "case": "A5"}
        ```
        SonuÃ§: `kitaplarda` (kitap + lar + da)
        """
        result = _generator.generate_noun(
            req.stem, req.plural, req.possessive, req.poss_type, req.case
        )
        if not result.is_valid:
            raise HTTPException(status_code=400, detail=result.error)
        return GenerateResponse(
            result=result.word,
            breakdown=result.breakdown,
            stem=result.stem,
            morphemes=_format_morphemes(result.morphemes, req.possessive),
            valid=result.is_valid
        )

    @app.post("/generate/verb", response_model=GenerateResponse, tags=["Generation"],
              summary="Fiil Ã§ekimi (Ã¼retim)")
    async def generate_verb(req: VerbGenerateRequest):
        """
        Fiil Ã§ekimi yapar.

        **Zorunlu alanlar**: `stem`, `tense`, `person`

        ```json
        {"stem": "gel", "tense": "1", "person": "A1"}
        ```
        SonuÃ§: `geldim` (gel + di + m)

        **Olumsuz**:
        ```json
        {"stem": "gel", "tense": "1", "person": "A1", "negative": true}
        ```
        SonuÃ§: `gelmedim`
        """
        result = _generator.generate_verb(
            req.stem, req.tense, req.person, req.negative
        )
        if not result.is_valid:
            raise HTTPException(status_code=400, detail=result.error)
        return GenerateResponse(
            result=result.word,
            breakdown=result.breakdown,
            stem=result.stem,
            morphemes=_format_morphemes(result.morphemes),
            valid=result.is_valid
        )

    @app.post("/generate", response_model=GenerateResponse, tags=["Generation"],
              summary="BirleÅŸik Ã¼retim (isim veya fiil)")
    async def generate(req: UnifiedGenerateRequest):
        """
        Ä°sim veya fiil Ã§ekimini tek endpoint'ten yapar.

        **Ä°sim Ã§ekimi** (`type: "noun"`):
        ```json
        {"type": "noun", "stem": "kitap", "possessive": "A1"}
        ```

        **Fiil Ã§ekimi** (`type: "verb"` â€” tense ve person zorunlu):
        ```json
        {"type": "verb", "stem": "gel", "tense": "1", "person": "A1"}
        ```
        """
        if req.type == "noun":
            result = _generator.generate_noun(req.stem, req.plural, req.possessive, req.poss_type, req.case)
            morphemes = _format_morphemes(result.morphemes, req.possessive)
        elif req.type == "verb":
            if not req.tense or not req.person:
                raise HTTPException(
                    status_code=400,
                    detail="Fiil Ã§ekimi iÃ§in 'tense' (zaman: 1-7) ve 'person' (ÅŸahÄ±s: A1-B3) alanlarÄ± zorunludur. "
                           "Ã–rnek: {\"type\": \"verb\", \"stem\": \"gel\", \"tense\": \"1\", \"person\": \"A1\"}"
                )
            result = _generator.generate_verb(req.stem, req.tense, req.person, req.negative)
            morphemes = _format_morphemes(result.morphemes)
        else:
            raise HTTPException(
                status_code=400,
                detail=f"GeÃ§ersiz tÃ¼r: '{req.type}'. 'noun' (isim) veya 'verb' (fiil) kullanÄ±n."
            )

        if not result.is_valid:
            raise HTTPException(status_code=400, detail=result.error)

        return GenerateResponse(
            result=result.word,
            breakdown=result.breakdown,
            stem=result.stem,
            morphemes=morphemes,
            valid=result.is_valid
        )

    @app.post("/analyze", response_model=AnalyzeResponse, tags=["Analysis"],
              summary="Morfolojik analiz (kelime Ã§Ã¶zÃ¼mleme)")
    async def analyze(req: AnalyzeRequest):
        """
        Ã‡ekimli bir kelimeyi kÃ¶kÃ¼ne ve eklerine ayÄ±rÄ±r.

        ```json
        {"word": "kitabym"}
        ```
        SonuÃ§: kÃ¶k = `Kitap`, ekler = `ym (Dâ‚b)`

        Hem isim hem fiil Ã§ekimlerini otomatik algÄ±lar.
        """
        multi = _analyzer.parse(req.word)
        results_list = []
        for r in multi.results:
            results_list.append(AnalyzeSingleResult(
                stem=r.stem,
                word_type=r.word_type,
                breakdown=r.breakdown,
                suffixes=r.suffixes,
                meaning=r.meaning
            ))
        return AnalyzeResponse(
            word=multi.original,
            success=multi.success,
            count=multi.count,
            results=results_list
        )

    @app.get("/lexicon/{word}", response_model=LexiconResponse, tags=["Lexicon"],
             summary="SÃ¶zlÃ¼k sorgusu")
    async def lexicon_lookup(word: str):
        """
        SÃ¶zlÃ¼kte kelime arar.

        Ã–rnek: `GET /lexicon/kitap` â†’ kelime tÃ¼rÃ¼, morfolojik Ã¶zellikler
        """
        entries = _lexicon.lookup(word)
        found = len(entries) > 0

        entry_list = []
        pos_display = None
        for entry in entries:
            entry_list.append({
                "word": entry.word,
                "pos": entry.pos,
                "features": entry.features
            })
            if pos_display is None:
                pos_display = POS_DISPLAY.get(entry.pos)

        return LexiconResponse(
            word=word,
            found=found,
            entries=entry_list,
            pos_display=pos_display
        )

    # ---- Spellcheck Endpoints ----

    @app.post("/spellcheck", response_model=SpellcheckResponse,
              tags=["Spellcheck"], summary="YazÄ±m denetimi")
    async def spellcheck(req: SpellcheckRequest):
        """
        Metin iÃ§indeki kelimelerin yazÄ±mÄ±nÄ± kontrol eder.

        Her kelime analyzer ile Ã§Ã¶zÃ¼mlenir:
        - Ã‡Ã¶zÃ¼mleme baÅŸarÄ±lÄ±ysa â†’ **doÄŸru**
        - Ã‡Ã¶zÃ¼mleme bulunamazsa â†’ **yanlÄ±ÅŸ** + Ã¶neri listesi

        ```json
        {"text": "men kitabym okadym"}
        ```

        SonuÃ§: `kitabym` âœ… doÄŸru, `okadym` âŒ yanlÄ±ÅŸ â†’ Ã¶neriler: [`okadym`...]
        """
        tokens = tokenize(req.text)
        results = []
        error_count = 0

        for tok in tokens:
            w = tok["word"]
            multi = _analyzer.parse(w)

            # Kelime doÄŸru mu? (en az 1 bilinen kÃ¶kle Ã§Ã¶zÃ¼mlenebiliyorsa)
            is_correct = False
            analysis_str = None

            if multi.success and multi.results:
                for r in multi.results:
                    if r.word_type != "unknown":
                        is_correct = True
                        analysis_str = r.breakdown
                        break

            suggestions = []
            if not is_correct:
                error_count += 1
                suggestions = generate_suggestions(w, _analyzer, _lexicon, max_suggestions=5)

            results.append(SpellcheckWordResult(
                word=w,
                correct=is_correct,
                start=tok["start"],
                end=tok["end"],
                suggestions=suggestions,
                analysis=analysis_str
            ))

        return SpellcheckResponse(
            text=req.text,
            word_count=len(tokens),
            error_count=error_count,
            results=results
        )

    @app.post("/spellcheck/batch", response_model=SpellcheckResponse,
              tags=["Spellcheck"], summary="Toplu yazÄ±m denetimi")
    async def spellcheck_batch(req: SpellcheckBatchRequest):
        """
        Kelime listesi Ã¼zerinde yazÄ±m denetimi yapar.

        ```json
        {"words": ["kitabym", "okadym", "mugalym"]}
        ```
        """
        results = []
        error_count = 0
        offset = 0

        for w in req.words:
            multi = _analyzer.parse(w)

            is_correct = False
            analysis_str = None

            if multi.success and multi.results:
                for r in multi.results:
                    if r.word_type != "unknown":
                        is_correct = True
                        analysis_str = r.breakdown
                        break

            suggestions = []
            if not is_correct:
                error_count += 1
                suggestions = generate_suggestions(w, _analyzer, _lexicon, max_suggestions=5)

            results.append(SpellcheckWordResult(
                word=w,
                correct=is_correct,
                start=offset,
                end=offset + len(w),
                suggestions=suggestions,
                analysis=analysis_str
            ))
            offset += len(w) + 1

        return SpellcheckResponse(
            text=" ".join(req.words),
            word_count=len(req.words),
            error_count=error_count,
            results=results
        )

    # ---- Paradigma Endpoints ----

    class ParadigmaRequest(BaseModel):
        """Paradigma tablosu isteÄŸi."""
        stem: str = Field(
            ...,
            description="Ä°sim veya fiil kÃ¶kÃ¼ (Ã¶r. kitap, gel)",
            json_schema_extra={"example": "kitap"}
        )
        type: str = Field(
            "noun",
            description="Kelime tÃ¼rÃ¼: 'noun' (isim) veya 'verb' (fiil)"
        )

        model_config = {
            "json_schema_extra": {
                "examples": [
                    {"summary": "Ä°sim paradigmasÄ±", "value": {"stem": "kitap", "type": "noun"}},
                    {"summary": "Fiil paradigmasÄ±", "value": {"stem": "gel", "type": "verb"}}
                ]
            }
        }

    class ParadigmaNounRow(BaseModel):
        """Ä°sim paradigma tablosu satÄ±rÄ±."""
        case_code: str = Field(..., description="Hal kodu")
        case_name: str = Field(..., description="Hal adÄ±")
        base: str = Field(..., description="YalÄ±n form")
        possA1: str = Field("", description="Dâ‚b (meniÅˆ)")
        possA2: str = Field("", description="Dâ‚‚b (seniÅˆ)")
        possA3: str = Field("", description="Dâ‚ƒb (onuÅˆ)")

    class ParadigmaNounResponse(BaseModel):
        """Ä°sim paradigma tablosu."""
        stem: str
        type: str = "noun"
        singular: list[ParadigmaNounRow] = Field(..., description="Tekil paradigma")
        plural: list[ParadigmaNounRow] = Field(..., description="Ã‡oÄŸul paradigma")

    class ParadigmaVerbRow(BaseModel):
        """Fiil paradigma tablosu satÄ±rÄ±."""
        person_code: str
        person_name: str
        positive: str = ""
        negative: str = ""

    class ParadigmaVerbTense(BaseModel):
        """Bir zaman iÃ§in paradigma."""
        tense_code: str
        tense_name: str
        rows: list[ParadigmaVerbRow]

    class ParadigmaVerbResponse(BaseModel):
        """Fiil paradigma tablosu."""
        stem: str
        type: str = "verb"
        tenses: list[ParadigmaVerbTense]

    CASE_NAMES = {
        None: ("â€”", "BaÅŸ dÃ¼ÅŸÃ¼m (YalÄ±n)"),
        "A2": ("Aâ‚‚", "EÃ½elik dÃ¼ÅŸÃ¼m (Ä°lgi)"),
        "A3": ("Aâ‚ƒ", "Barlag dÃ¼ÅŸÃ¼m (YÃ¶nelme)"),
        "A4": ("Aâ‚„", "Tabyn dÃ¼ÅŸÃ¼m (Belirtme)"),
        "A5": ("Aâ‚…", "Ãerlik dÃ¼ÅŸÃ¼m (Bulunma)"),
        "A6": ("Aâ‚†", "Ã‡ykyÅŸ dÃ¼ÅŸÃ¼m (Ã‡Ä±kma)"),
    }

    TENSE_NAMES = {
        "1": "Anyk Ã¶ten zaman",
        "2": "DaÅŸ Ã¶ten zaman",
        "3": "Dowamly Ã¶ten zaman",
        "4": "Umumy hÃ¤zirki zaman",
        "5": "Anyk hÃ¤zirki zaman",
        "6": "MÃ¤lim geljek zaman",
        "7": "NÃ¤mÃ¤lim geljek zaman",
    }

    PERSON_NAMES = {
        "A1": "Men", "A2": "Sen", "A3": "Ol",
        "B1": "Biz", "B2": "Siz", "B3": "Olar",
    }

    @app.post("/paradigm", tags=["Paradigm"],
              summary="Paradigma tablosu oluÅŸtur")
    async def paradigm(req: ParadigmaRequest):
        """
        Bir kelimenin tam Ã§ekim paradigmasÄ±nÄ± dÃ¶ndÃ¼rÃ¼r.

        **Ä°sim:**  6 hal Ã— 4 iyelik (yalÄ±n, A1, A2, A3) Ã— tekil/Ã§oÄŸul = 48 form
        **Fiil:**   7 zaman Ã— 6 ÅŸahÄ±s Ã— olumlu/olumsuz = 84 form

        ```json
        {"stem": "kitap", "type": "noun"}
        ```
        """
        if req.type == "noun":
            return _generate_noun_paradigm(req.stem)
        elif req.type == "verb":
            return _generate_verb_paradigm(req.stem)
        else:
            raise HTTPException(status_code=400,
                                detail=f"GeÃ§ersiz tÃ¼r: '{req.type}'")

    def _generate_noun_paradigm(stem: str) -> ParadigmaNounResponse:
        """Ä°sim paradigma tablosu oluÅŸturur."""
        cases = [None, "A2", "A3", "A4", "A5", "A6"]
        poss_codes = [None, "A1", "A2", "A3"]

        singular_rows = []
        plural_rows = []

        for case in cases:
            code, name = CASE_NAMES[case]

            # Tekil
            s_row = {"case_code": code, "case_name": name}
            for poss in poss_codes:
                r = _generator.generate_noun(stem, plural=False,
                                              possessive=poss, case=case)
                key = "base" if poss is None else f"poss{poss}"
                s_row[key] = r.word if r.is_valid else "â€”"
            singular_rows.append(ParadigmaNounRow(**s_row))

            # Ã‡oÄŸul
            p_row = {"case_code": code, "case_name": name}
            for poss in poss_codes:
                r = _generator.generate_noun(stem, plural=True,
                                              possessive=poss, case=case)
                key = "base" if poss is None else f"poss{poss}"
                p_row[key] = r.word if r.is_valid else "â€”"
            plural_rows.append(ParadigmaNounRow(**p_row))

        return ParadigmaNounResponse(stem=stem,
                                      singular=singular_rows,
                                      plural=plural_rows)

    def _generate_verb_paradigm(stem: str) -> ParadigmaVerbResponse:
        """Fiil paradigma tablosu oluÅŸturur."""
        tenses = []
        persons = ["A1", "A2", "A3", "B1", "B2", "B3"]

        for t_code in ["1", "2", "3", "4", "5", "6", "7"]:
            rows = []
            for p_code in persons:
                pos_r = _generator.generate_verb(stem, t_code, p_code, negative=False)
                neg_r = _generator.generate_verb(stem, t_code, p_code, negative=True)
                rows.append(ParadigmaVerbRow(
                    person_code=p_code,
                    person_name=PERSON_NAMES[p_code],
                    positive=pos_r.word if pos_r.is_valid else "â€”",
                    negative=neg_r.word if neg_r.is_valid else "â€”",
                ))
            tenses.append(ParadigmaVerbTense(
                tense_code=t_code,
                tense_name=TENSE_NAMES[t_code],
                rows=rows,
            ))

        return ParadigmaVerbResponse(stem=stem, tenses=tenses)

else:
    # FastAPI yoksa dummy app
    app = None
    print("UYARI: FastAPI kurulu deÄŸil. API kullanabilmek iÃ§in: pip install fastapi uvicorn")
